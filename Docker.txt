//修改ubuntu分辨率
VMware中的Ubuntu Server的控制台窗口有点儿小，使用起来不太方便，要调整控制台的窗口大小，需要修改屏幕的分辨率，修改方法如下：（参见Reference）
 1. 打开grub文件($sudo vim /etc/default/grub), 修改参数
GRUB_CMDLINE_LINUX="vga=0x317", 参数值参考下图：
Colours    640x480  800x600  1024x768  1152x864  1280x1024  1600x1200
256 色    0x301     0x303    0x305        0x161      0x307      0x31C
32k 色    0x310     0x313      0x316        0x162      0x319         0x31D
64k 色    0x311     0x314      0x317        0x163      0x31A         0x31E
16m 色    0x312     0x315      0x318        ?          0x31B         0x31F

$sudo update-grub
$sudo reboot

//压缩文件夹
sudo tar zcvf work.tar.gz work/
//解压缩文件
tar xzvf work.tar.gz


//安装配置ssh服务
https://www.cnblogs.com/hslzju/p/5839913.html
apt install openssh-server
//修改配置文件
root@ea153153c883:/etc/ssh# 
vim /etc/ssh/sshd_config 
sshd_config 这里先修改两处：
PermitRootLogin without-password 改为 PermitRootLogin yes
#PasswordAuthentication yes 改为 PasswordAuthentication yes
//重启服务
service ssh start
//设置root密码
passwd root
//生成公钥
ssh-keygen -t rsa
//在远程机器上登录
ssh root@172.17.0.2


//设置防火墙允许端口
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw  reload


//编辑ubuntu的host文件
sudo vim /etc/hosts
192.168.56.101 howtoing.local


//Ubuntu18.04安装mysql5.7
sudo apt install mysql-server mysql-client libmysqlclient-dev
# 检查状态
sudo netstat -tap | grep mysql
#设置root密码
//mysql5.7安装完成后普通用户不能进mysql，原因：root的plugin被修改成了auth_socket，用密码登陆的plugin应该是mysql_native_password，直接用root权限登录就不用密码,修改root密码和登录验证方式：
$ sudo su
# mysql
mysql>
mysql> select user, plugin from mysql.user;
+------------------+-----------------------+
| user             | plugin                |
+------------------+-----------------------+
| root             | auth_socket           |
| mysql.session    | mysql_native_password |
| mysql.sys        | mysql_native_password |
| debian-sys-maint | mysql_native_password |
+------------------+-----------------------+
4 rows in set (0.00 sec)
mysql> update mysql.user set plugin='mysql_native_password' where user='root';
mysql> flush privileges;
mysql> exit
Bye
# exit
$ sudo /etc/init.d/mysql restart
$ mysql -uroot -p
1.3配置mysql远程登录
# 修改配置文件，注释掉bind-address = 127.0.0.1
$ sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf
# 保存退出，然后进入mysql服务，执行授权命令：
$ mysql -uroot -p
mysql> grant all on *.* to root@'%' identified by '123456' with grant option;
Query OK, 0 rows affected, 1 warning (0.00 sec)
mysql> flush privileges;
Query OK, 0 rows affected (0.00 sec)
mysql> exit
Bye
$ sudo /etc/init.d/mysql restart

//安装mysql主从复制
https://www.cnblogs.com/gl-developer/p/6170423.html
//解决克隆server导致UUID冲突问题
https://blog.csdn.net/helloxiaozhe/article/details/81150763
//解决主从同步错误
http://www.jquerycn.cn/a_24338
//设置复制范围
# 不同步哪些数据库  
binlog-ignore-db = mysql  
binlog-ignore-db = test  
binlog-ignore-db = information_schema  
  # 只同步哪些数据库，除此之外，其他不同步  
binlog-do-db = game  

//安装nginx
sudo apt install nginx
//nginx配置
配置文件：/etc/nginx/
主程序文件：/usr/sbin/nginx
Web默认目录：/usr/share/nginx/http/
日志目录：/var/log/nginx/
//操作nginx
service nginx start
service nginx stop
//查看进程
ps -ef | grep nginx



//ubuntu16设置静态IP
ens33:
addresses: [192.168.1.20/24]
dhcp4: false
gateway4: 192.168.1.1
nameservers:
addresses: [192.168.1.1]
optional: true
version: 2

1、service network restart：重启网络服务
2、ifconfig eth0 down ; ifconfig eth0 up：对网卡进行操作
3、sudo dhclient -r//release ip：释放IP
4、sudo dhclient//：获取IP



//Docker中国 
https://www.docker-cn.com/
//安装docker
https://blog.csdn.net/pushiqiang/article/details/78682323
//删除镜像
docker rmi 镜像ID/名称
//查看运行的容器 -a 所有 -q 显示ID
docker ps -a
//启动已被停止的容器myrunoob
docker start myrunoob
//停止运行中的容器myrunoob
docker stop myrunoob
//重启容器myrunoob
docker restart myrunoob
//删除容器
docker rm 容器ID/名称
//批量停止容器
sudo docker stop $(sudo docker ps -a -q)
//批量删除容器
sudo docker rm $(sudo docker ps -a -q)

//安装docker compose  官网：https://docs.docker.com/compose/install/#install-compose
sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose --version
docker-compose version 1.22.0, build f46880fe
  

//更新运行中的Docker容器重启策略    
docker update --restart=always <CONTAINER ID>

//查看容器信息
docker inspect 容器ID/名称

//创建网络 --subnet=子网段 
docker network 网络名称
docker network create --subnet=172.0.0.0/16 amnp-net

//将容器加入网络
docker network connect 网络名称 容器ID/名称 


 **************************************************************  数据卷  ****************************************************************
//创建数据卷容器(/data目录为保存数据的目录) 数据卷名称:app-data
docker run -itd -v /var/lib/mysql -v /etc/apache2 -v /etc/mysql --name dv_appdata alpine:3.8 /bin/sh


//其它容器使用数据卷容器
docker run -itd --name web1 --volumes-from dv_appdata ubuntu

//通过临时容器备份数据容器卷 
//数据容器名称：dvdata    /etc目录为数据卷容器内的保存数据的目录
//docker宿主机备份目录/container_backup
//临时容器目录/backup    ubuntu 临时容器镜像名
docker run --rm --volumes-from dvdata -v /app:/backup ubuntu tar cvf /backup/aaa.tar /etc
docker run --rm --volumes-from dvdata -v /container_backup:/backup ubuntu tar cvf /backup/backup.tar /data

//恢复数据卷容器 创建数据卷容器
docker run -v /data --name dvdata2 ubuntu
//将数据恢复到临时容器，同时恢复到数据卷容器
docker run --volumes-from dvdata2 -v /container_backup:/backup ubuntu tar xvf /backup/backup.tar



*********************************************************  NGINX  *************************************************************
//启动nginx容器,需要事先在/home/nginx/conf/目录中建立nginx.conf文件，否则配置文件挂载不上
docker run \
 --name jhz_nginx \
 --restart=always \
 -p 8082:80 \
 -d \
 -v dv-jhz-nginx-html:/usr/share/nginx/html \
 -v dv-jhz-nginx-logs:/wwwlogs \
 -v dv-jhz-nginx-conf:/etc/nginx/conf.d \
 nginx:1.15.3-alpine \
 nginx -g 'daemon off;'

 --network amnp-net \
 --ip 172.0.0.3 \
 
//以下方法进入虚拟机控制台
docker exec -it jhz_nginx /bin/bash 


**********************************************************  mysql ************************************************************
//启动mysql容器-linux
docker run \
 --name mmm1 \
 --restart=always \
 -p 3301:3306 \
 -d \
 -v dv-mmm1-data:/var/lib/mysql \
 -v dv-mmm1-conf:/etc/mysql \
 -e MYSQL_ROOT_PASSWORD=123456 \
 mysql:5.6

 
 --network amnp-net \
 --ip 172.0.0.4 \
 -v dv-jhz-mysql-logs:/var/log/mysql \
 

***************************************************  ubuntu16 php laravel 集成部署环境 ****************************************************

docker run \
 --name fusion_plantform \
 -p 8081:80 \
 -p 3307:3306 \
 -p 5023:22 \
 -itd  \
 ubuntu:16.04 /bin/bash
 
//进入容器内部开始安装环境
docker exec -it fusion_plantform  /bin/bash 

apt update
apt upgrade
apt clean
apt autoclean
apt autoremove

//设置字符集  可选
apt install language-pack-en-base
locale-gen en_US.UTF-8
apt install software-properties-common
LC_ALL=en_US.UTF-8 add-apt-repository ppa:ondrej/php


//安装文本编辑器
apt install vim

//安装apache2
apt install apache2
//配置apache2 
vim /etc/apache2/apache2.conf //编辑配置文件,在空白处添加下面的配置
ServerName localhost
//启动apache2
service apache2  restart
//测试apache2 访问apache 显示 Apache2 Ubuntu Default Page
http://192.168.7.227:8081/
//查看aapche版本
Apache2 -v

//安装mysql5.7
apt install mysql-server mysql-client libmysqlclient-dev
//启动mysql报错：No directory, logging in with HOME=/ 解决办法
usermod -d /var/lib/mysql/ mysql   #第一步
ln -s /var/lib/mysql/mysql.sock /tmp/mysql.sock   #第二步
chown -R mysql:mysql /var/lib/mysql   #第三步
//后期挂载数据目录到卷的时候默认docker是由root用户操作，因此mysql用户需要加入root组才能正常访问这个目录
usermod -a -G root mysql
//登录mysql 修改远程登录
$ mysql -uroot -p
mysql> grant all on *.* to root@'%' identified by '123456' with grant option;
mysql> flush privileges;
mysql> exit
# 修改配置文件，注释掉bind-address = 127.0.0.1
vim /etc/mysql/mysql.conf.d/mysqld.cnf
//重启数据库
/etc/init.d/mysql restart
//生产环境设置数据库安全(可选)
mysql_secure_installation

//安装php7
apt install php
//安装apache的php模块
apt install libapache2-mod-php
//建立php文件 phpinfo.php
<?php
 phpinfo(); 
?>
//测试aapche和php整合结果,访问以下地址,显示php配置信息页面
http://192.168.7.227:8081/phpinfo.php
//安装php扩展
apt install php7.0-fpm php7.0-mysql php7.0-common php7.0-curl php7.0-cli php7.0-mcrypt php7.0-mbstring php7.0-dom
apt install php-zip php7.0-xml php7.0-json php7.0-gd
//查看已经安装的php模块
php -m

//重启容器,确认各种服务正常访问
docker restart  fusion_plantform
docker exec -it fusion_plantform service apache2 restart //在容器外启动apache服务
docker exec -it fusion_plantform service mysql restart    //在容器外启动mysql服务
//将容器提交为镜像
docker commit fusion_plantform fff:1.0

//从镜像启动新容器
docker run \
 --name fff2 \
 -p 8082:80 \
 -p 3308:3306 \
 -p 5024:22 \
 -itd  \
 -v fp-apache-www:/var/www/html \
 -v fp-apache-conf:/etc/apache2 \
 -v fp-mysql-data:/var/lib/mysql \
 fff:1.0 /bin/bash
//启动服务 //在容器外启动apache服务  //在容器外启动mysql服务
docker exec -it fff2 service apache2 restart 
docker exec -it fff2 service mysql restart   

//安装composer工具
apt install composer
//下载laravel依赖
composer global require "laravel/installer"
# 修改环境变量,将laravel命令加到PATH末尾
export PATH=$PATH:~/.composer/vendor/bin
//创建测试项目 laravel5.5
composer create-project --prefer-dist laravel/laravel blog 5.5


**************************************************************  portainer  ****************************************************************
#docker容器管理UI工具
docker run -d -p 9000:9000 \
    --restart=always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    --name prtainer-test \
    portainer/portainer
    
*********************************************************  docker 私有仓库 registry ********************************************************

docker run -d -p 5000:5000 --restart always --name registry registry:2
docker run -d \
  -p 5000:5000 \
  --restart=always \
  --name registry \
  -v /mnt/registry:/var/lib/registry \
  registry:2
  
  
docker run -d --restart=always -p 8080:8080 --name registry-web --link registry -e REGISTRY_URL=http://192.168.50.59:5000/v2 -e REGISTRY_NAME=192.168.50.59:5000 hyper/docker-registry-web


*********************************************************  K8s安装 ********************************************************
使用root用户安装

#关闭交换内存
swapoff -a
#修改配置文件关闭交换内存,注释其中swap相关行
vi /etc/fstab
# 查看是否关闭交换内存
free -m


#查看可用版本
apt-cache madison docker-ce
apt-cache madison docker-ce-cli
#安装指定版本docker
sudo apt-get install docker-ce=5:18.09.8~3-0~ubuntu-bionic \
sudo apt-get install docker-ce-cli=5:18.09.8~3-0~ubuntu-bionic \
sudo apt-get install containerd.io \

#更新
apt-get update && apt-get install -y apt-transport-https
#安装证书
curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 
#编辑k8s源
vim /etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
apt-get update

#拉取K8S相关镜像
docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.14.3
docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.14.3
docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.14.3
docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.14.3
docker pull mirrorgooglecontainers/pause:3.1
docker pull mirrorgooglecontainers/etcd-amd64:3.3.10
docker pull coredns/coredns:1.3.1
#给docker镜像打tag
docker tag mirrorgooglecontainers/kube-apiserver-amd64:v1.14.3 k8s.gcr.io/kube-apiserver:v1.14.3
docker tag mirrorgooglecontainers/kube-controller-manager-amd64:v1.14.3 k8s.gcr.io/kube-controller-manager:v1.14.3
docker tag mirrorgooglecontainers/kube-scheduler-amd64:v1.14.3 k8s.gcr.io/kube-scheduler:v1.14.3
docker tag mirrorgooglecontainers/kube-proxy-amd64:v1.14.3 k8s.gcr.io/kube-proxy:v1.14.3
docker tag mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1
docker tag mirrorgooglecontainers/etcd-amd64:3.3.10 k8s.gcr.io/etcd:3.3.10
docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1

#安装k8S基础组件
apt-get install -y kubelet=1.14.3-00 kubeadm=1.14.3-00 kubectl=1.14.3-00
#编辑Docker配置文件,添加下面内容,适配K8S的文件系统
vim /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"]
}

#初始化Master节点
kubeadm init --kubernetes-version=v1.14.3 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 
#初始化完成后显示下面的内容,需要执行其中的三条命令
------------------------------------------
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 10.0.0.17:6443 --token o41vfj.wnoe4to53697nu56 \
    --discovery-token-ca-cert-hash sha256:5c8a89fff536197e272c7cd1263d2bc37be20fda144086e9fb6e986acea019c2 
-----------------------------------------------------------------------------------

#k8S核心组件
ls /etc/kubernetes/manifests/
etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml

kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml


#安装kubernetes-dashboard
docker pull mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1
docker tag mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.10.1 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1
#注意脚本中的版本号                                                  k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1


wget http://pencil-file.oss-cn-hangzhou.aliyuncs.com/blog/kubernetes-dashboard.yaml

# ------------------- Dashboard Service ------------------- #

kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kube-system
spec:
  type: NodePort    # 新增
  ports:
    - port: 443
      targetPort: 8443
  selector:
    k8s-app: kubernetes-dashboard
......

kubectl create -f  kubernetes-dashboard.yaml


[root@k8snode1 kubernetes]# kubectl get pod
The connection to the server localhost:8080 was refused - did you specify the right host or port?
#出现这个问题的原因是kubectl命令需要使用kubernetes-admin来运行，解决方法如下，将主节点中的【/etc/kubernetes/admin.conf】文件拷贝到从节点相同目录下，然后配置环境变量：
echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bash_profile
立即生效
source ~/.bash_profile

#查看面板的运行状态
kubectl get deployment kubernetes-dashboard -n kube-system
NAME                   READY   UP-TO-DATE   AVAILABLE   AGE
kubernetes-dashboard   1/1     1            1           31s

#查看pod运行状态
kubectl get pods -n kube-system -o wide
NAME                                    READY   STATUS    RESTARTS   AGE    IP           NODE        NOMINATED NODE   READINESS GATES
coredns-fb8b8dccf-ddbvg                 1/1     Running   5          14h    10.244.0.4   localhost   <none>           <none>
coredns-fb8b8dccf-rxjnb                 1/1     Running   4          14h    10.244.0.3   localhost   <none>           <none>
etcd-localhost                          1/1     Running   1          14h    10.0.0.17    localhost   <none>           <none>
kube-apiserver-localhost                1/1     Running   4          14h    10.0.0.17    localhost   <none>           <none>
kube-controller-manager-localhost       1/1     Running   21         14h    10.0.0.17    localhost   <none>           <none>
kube-flannel-ds-amd64-lrv4w             1/1     Running   0          6h4m   10.0.0.17    localhost   <none>           <none>
kube-proxy-q897v                        1/1     Running   1          14h    10.0.0.17    localhost   <none>           <none>
kube-scheduler-localhost                1/1     Running   16         14h    10.0.0.17    localhost   <none>           <none>
kubernetes-dashboard-5f57845f9d-d2hpj   1/1     Running   0          116s   10.244.0.6   localhost   <none>           <none>

#查看服务运行状态
kubectl get services -n kube-system
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE
kube-dns               ClusterIP   10.96.0.10      <none>        53/UDP,53/TCP,9153/TCP   14h
kubernetes-dashboard   NodePort    10.101.98.185   <none>        443:30414/TCP            2m42s

#查看访问Dashboard的认证令牌
kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk ‘/dashboard-admin/{print $1}’)

#创建dashboard管理用户
kubectl create serviceaccount dashboard-admin -n kube-system

#绑定用户为集群管理用户
kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin

#获取tocken
kubectl describe secret -n kube-system dashboard-admin
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tbTZianAiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNmQyYzRkMzMtYmI0OC0xMWU5LTgxY2EtMDAwYzI5MWEzODdhIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.NUplen7k7iJKiDgyyL7CTb38dXy2ixvfjVqLDw9N5YVh6KkCHYm6MyHVl7owVh47mwSITZCaw8ashEU1XrvU60Vl0md6GrDdlyAnY6k-UZCB03NeRxNxYdWD4d0YbD82W-Do8F15Ujw6o-bXyN7HRRbQALEBh2SUEEGsSslxlrC3DLl8EqdJa_LYXrIu0nszioLDYQNoUKetzRrRKF63Bg0utO8NEdksQARE0iG4YPEdr8X1y3-I-7_i6vc9wWjriFNqIEaJAaqdHYshztxxFdLaMRz-fkWMUvW6bgn1gfKiBuCfM2BFlXvWo-K7OHU2oRPNgHBD6ukLZAc-2DDdUA


#仪表板的访问端口,使用火狐浏览器访问
https://10.0.0.17:30414/



#默认情况下kubernetes中的master并不能运行用户的Pod. 因此需要删除 Train，允许master执行Pod(仅仅在调试环境一台机器即做master又做node的情况下)
kubectl taint nodes --all node-role.kubernetes.io/master-

------------------------------- yaml 创建带数据卷的nginx POD  已成功 -------------------------------
apiVersion: v1
kind: Pod
metadata:
    name: test-pd-1
    labels:
        app: lb-1
spec:
    containers:
      - name: test-container
        image: nginx:alpine
        ports:              
            - containerPort: 80
        volumeMounts:
            - mountPath: /usr/share/nginx/html
              name: cache-volume
    volumes:
        - name: cache-volume
          emptyDir: {}
  


---------------------------------- - yaml格式的pod定义文件完整内容：-----------------------------------------------
apiVersion: v1       #必选，版本号，例如v1
kind: Pod       #必选，Pod
metadata:       #必选，元数据
  name: string       #必选，Pod名称
  namespace: string    #必选，Pod所属的命名空间
  labels:      #自定义标签
    - name: string     #自定义标签名字
  annotations:       #自定义注释列表
    - name: string
spec:         #必选，Pod中容器的详细定义
  containers:      #必选，Pod中容器列表
  - name: string     #必选，容器名称
    image: string    #必选，容器的镜像名称
    imagePullPolicy: [Always | Never | IfNotPresent] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像
    command: [string]    #容器的启动命令列表，如不指定，使用打包时使用的启动命令
    args: [string]     #容器的启动命令参数列表
    workingDir: string     #容器的工作目录
    volumeMounts:    #挂载到容器内部的存储卷配置
    - name: string     #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名
      mountPath: string    #存储卷在容器内mount的绝对路径，应少于512字符
      readOnly: boolean    #是否为只读模式
    ports:       #需要暴露的端口库号列表
    - name: string     #端口号名称
      containerPort: int   #容器需要监听的端口号
      hostPort: int    #容器所在主机需要监听的端口号，默认与Container相同
      protocol: string     #端口协议，支持TCP和UDP，默认TCP
    env:       #容器运行前需设置的环境变量列表
    - name: string     #环境变量名称
      value: string    #环境变量的值
    resources:       #资源限制和请求的设置
      limits:      #资源限制的设置
        cpu: string    #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数
        memory: string     #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数
      requests:      #资源请求的设置
        cpu: string    #Cpu请求，容器启动的初始可用数量
        memory: string     #内存清楚，容器启动的初始可用数量
    livenessProbe:     #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可
      exec:      #对Pod容器内检查方式设置为exec方式
        command: [string]  #exec方式需要制定的命令或脚本
      httpGet:       #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port
        path: string
        port: number
        host: string
        scheme: string
        HttpHeaders:
        - name: string
          value: string
      tcpSocket:     #对Pod内个容器健康检查方式设置为tcpSocket方式
         port: number
       initialDelaySeconds: 0  #容器启动完成后首次探测的时间，单位为秒
       timeoutSeconds: 0   #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒
       periodSeconds: 0    #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次
       successThreshold: 0
       failureThreshold: 0
       securityContext:
         privileged:false
    restartPolicy: [Always | Never | OnFailure]#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod
    nodeSelector: obeject  #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定
    imagePullSecrets:    #Pull镜像时使用的secret名称，以key：secretkey格式指定
    - name: string
    hostNetwork:false      #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络
    volumes:       #在该pod上定义共享存储卷列表
    - name: string     #共享存储卷名称 （volumes类型有很多种）
      emptyDir: {}     #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值
      hostPath: string     #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录
        path: string     #Pod所在宿主机的目录，将被用于同期中mount的目录
      secret:      #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部
        scretname: string  
        items:     
        - key: string
          path: string
      configMap:     #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部
        name: string
        items:
        - key: string
          path: string



	
------------------------------- 创建一个部署（含nginx容器和数据卷）创建一个服务来暴露端口  成功 -------------------------------


apiVersion: apps/v1beta1   #API版本
kind: Deployment           #创建类型 部署
metadata:                             #元数据
    name: deployment-example  #部署名称
spec:
    replicas: 1               #副本数量
    revisionHistoryLimit: 10   #副本历史数量
    selector:                  #标签选择器
        matchLabels:           #匹配标签
            app: nginx         #匹配标签内容
    template:                  #pod模板
        metadata:              #元数据
            labels:            #标签定义
                app: nginx     #pod标签
        spec:
            containers:        #容器定义 
              - name: test-container   #容器名称
                image: nginx:alpine    #容器镜像及版本
                ports:                 #容器端口定义
                    - containerPort: 80  #容器端口号
                volumeMounts:             #数据卷定义
                    - mountPath: /usr/share/nginx/html    #数据卷容器内挂载地址
                      name: cache-volume                  #数据卷名称，用于匹配数据卷定义部分的名称
            volumes:                                      #数据卷定义
                - name: cache-volume                      #数据卷名称
                  emptyDir: {}                            #数据卷类型及内容设置
				  
	          
kind: Service
apiVersion: v1
metadata:
    name: my-service           #服务名称
spec:
    selector:
        app: nginx             #标签选择
    type: NodePort             #ClusterIP 内部服务 NodePort 指定外部端口（调试模式） LoadBalancer 独有IP外部访问
    ports:
      - protocol: TCP
        port: 8080      #POD端口
        targetPort: 80
        nodePort: 32222


kind: Service
apiVersion: v1
metadata:
    name: my-service1          
spec:
    selector:
        app: nginx             
    type: LoadBalancer             
    ports:
      - protocol: TCP
        port: 80
        targetPort: 80
		
---------------------------------------- yaml nvmp --------------------------------------------

apiVersion: apps/v1beta1   #API版本
kind: Deployment           #创建类型 部署
metadata:                             #元数据
    name: deployment-nvmp  #部署名称
spec:
    replicas: 1               #副本数量
    revisionHistoryLimit: 10   #副本历史数量
    selector:                  #标签选择器
        matchLabels:           #匹配标签
            app: nvmp         #匹配标签内容
    template:                  #pod模板
        metadata:              #元数据
            labels:            #标签定义
                app: nvmp     #pod标签
        spec:
            containers:        #容器定义 
              - name: nvmp-container   #容器名称
                image: 192.168.6.3:5000/cyberzone-nvmp:1.0    #容器镜像及版本
                command: ["/app/auto_service.sh"]
                ports:                 #容器端口定义
                    - containerPort: 80  #容器端口号
                volumeMounts:             #数据卷定义
                    - mountPath: /var/www    #数据卷容器内挂载地址
                      name: dv-nvmp-src                  #数据卷名称，用于匹配数据卷定义部分的名称
                    - mountPath: /var/log/apache2    #数据卷容器内挂载地址
                      name: dv-nvmp-log                  #数据卷名称，用于匹配数据卷定义部分的名称
            volumes:                                      #数据卷定义
                - name: dv-nvmp-src                      #数据卷名称
                  emptyDir: {}                            #数据卷类型及内容设置
                - name: dv-nvmp-log                        #数据卷名称
                  emptyDir: {}                            #数据卷类型及内容设置
				  
			
				  
				  
kind: Service
apiVersion: v1
metadata:
    name: nvmp-service          
spec:
    selector:
        app: nvmp         
    type: LoadBalancer             
    ports:
      - protocol: TCP
        port: 18080
        targetPort: 80
